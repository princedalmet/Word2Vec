{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1VnOfzT9K6uJoXgrnZxJU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princetondalmet/Word2Vec/blob/main/sim1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm_KL0ZsnmeJ"
      },
      "outputs": [],
      "source": [
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy  # For preprocessing\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "metadata": {
        "id": "h04dGSJHoPgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/grive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HF9TvjzofnY",
        "outputId": "9b169daf-5fb4-4947-a6db-b98a25733ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/grive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"simpsons_dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1duCvlTIo1z-",
        "outputId": "666f844e-d422-41f8-a012-3a352a4bac7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        raw_character_text                                       spoken_words\n",
              "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
              "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
              "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
              "3             Lisa Simpson                         That life is worth living.\n",
              "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa13c455-f566-4872-bc8f-34539d362d02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>spoken_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>That life is worth living.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>The polls will be open from now until the end ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa13c455-f566-4872-bc8f-34539d362d02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa13c455-f566-4872-bc8f-34539d362d02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa13c455-f566-4872-bc8f-34539d362d02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eCmCfajpBfo",
        "outputId": "3a75903f-5539-4269-f86a-29fdd831a25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    17814\n",
              "spoken_words          26459\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK9aarYapGR4",
        "outputId": "8c805f60-3bf6-436d-cd4f-80b9049c004f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "def cleaning(doc):\n",
        "    # Lemmatizes and removes stopwords\n",
        "    # doc needs to be a spacy Doc object\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
        "    # if a sentence is only one or two words long,\n",
        "    # the benefit for the training is very small\n",
        "    if len(txt) > 2:\n",
        "        return ' '.join(txt)"
      ],
      "metadata": {
        "id": "uUigNieHpQtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
      ],
      "metadata": {
        "id": "VHiKx9UopZsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UTac6RQpdEB",
        "outputId": "0a61ec14-4cc3-4204-afa7-770eafcfd0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to clean up everything: 1.17 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFYmAFRcplN6",
        "outputId": "4fd278a5-86fd-47eb-9469-b76e8dbca246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85964, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYR62AXspxs3",
        "outputId": "65f77adc-bd11-4c31-d124-a3bcd5512e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:53:34: 'pattern' package not found; tag filters are not available for English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = [row.split() for row in df_clean['clean']]"
      ],
      "metadata": {
        "id": "gIUCquUvp4gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsfh5y0p6Sn",
        "outputId": "fc32ad24-806f-4900-ad22-827a4549549a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:54:04: collecting all words and their counts\n",
            "INFO - 13:54:04: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 13:54:04: PROGRESS: at sentence #10000, processed 63561 words and 52816 word types\n",
            "INFO - 13:54:04: PROGRESS: at sentence #20000, processed 130943 words and 99866 word types\n",
            "INFO - 13:54:04: PROGRESS: at sentence #30000, processed 192972 words and 138532 word types\n",
            "INFO - 13:54:04: PROGRESS: at sentence #40000, processed 249842 words and 172659 word types\n",
            "INFO - 13:54:05: PROGRESS: at sentence #50000, processed 311265 words and 208566 word types\n",
            "INFO - 13:54:05: PROGRESS: at sentence #60000, processed 373588 words and 243702 word types\n",
            "INFO - 13:54:05: PROGRESS: at sentence #70000, processed 436441 words and 278740 word types\n",
            "INFO - 13:54:05: PROGRESS: at sentence #80000, processed 497829 words and 311886 word types\n",
            "INFO - 13:54:05: collected 330804 word types from a corpus of 537160 words (unigram + bigrams) and 85964 sentences\n",
            "INFO - 13:54:05: using 330804 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLvsXLwjp99x",
        "outputId": "fb147a9e-accd-4047-edba-4c0b9d85b1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:54:22: source_vocab length 330804\n",
            "INFO - 13:54:25: Phraser built with 126 phrasegrams\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = bigram[sent]"
      ],
      "metadata": {
        "id": "TOb2VuQaqCTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF3iJCILqEvX",
        "outputId": "30df14a3-8751-4354-84f4-d08214affae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30178"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG4UHQtaqIAo",
        "outputId": "b06f334c-1c98-48e8-bab6-86a724ef9945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oh', 'like', 'know', 'get', 'hey', 'think', 'right', 'look', 'want', 'come']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "zIM_bAKsqLDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
      ],
      "metadata": {
        "id": "N2ljquqLqOe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "metadata": {
        "id": "amETl-Z-qUXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbUYonMGqXim",
        "outputId": "9e16fc52-8cc7-498e-fc0b-e4d078fc77b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:56:04: collecting all words and their counts\n",
            "INFO - 13:56:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 13:56:04: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 13:56:04: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 13:56:04: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 13:56:05: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 13:56:05: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 13:56:05: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 13:56:05: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 13:56:06: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 13:56:06: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 13:56:06: Loading a fresh vocabulary\n",
            "INFO - 13:56:06: effective_min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n",
            "INFO - 13:56:06: effective_min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n",
            "INFO - 13:56:06: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 13:56:06: sample=6e-05 downsamples 1200 most-common words\n",
            "INFO - 13:56:06: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n",
            "INFO - 13:56:06: estimated required memory for 3319 words and 300 dimensions: 9625100 bytes\n",
            "INFO - 13:56:06: resetting layer weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to build vocab: 0.05 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMWRvPHoqbAH",
        "outputId": "30fd8ee2-a31d-4c24-df8a-f1deb6bc0933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:56:22: training model with 1 workers on 3319 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 13:56:23: EPOCH 1 - PROGRESS: at 27.49% examples, 55677 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:24: EPOCH 1 - PROGRESS: at 49.85% examples, 47369 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:25: EPOCH 1 - PROGRESS: at 67.17% examples, 42360 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:26: EPOCH 1 - PROGRESS: at 93.81% examples, 44809 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:26: EPOCH - 1 : training on 523700 raw words (198820 effective words) took 4.3s, 45972 effective words/s\n",
            "INFO - 13:56:27: EPOCH 2 - PROGRESS: at 29.42% examples, 60532 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:28: EPOCH 2 - PROGRESS: at 63.30% examples, 61198 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:29: EPOCH 2 - PROGRESS: at 95.68% examples, 61775 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:29: EPOCH - 2 : training on 523700 raw words (199218 effective words) took 3.2s, 62198 effective words/s\n",
            "INFO - 13:56:30: EPOCH 3 - PROGRESS: at 31.39% examples, 60622 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:32: EPOCH 3 - PROGRESS: at 65.21% examples, 61709 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:33: EPOCH 3 - PROGRESS: at 97.45% examples, 62230 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:33: EPOCH - 3 : training on 523700 raw words (199222 effective words) took 3.2s, 62477 effective words/s\n",
            "INFO - 13:56:34: EPOCH 4 - PROGRESS: at 29.42% examples, 59946 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:35: EPOCH 4 - PROGRESS: at 63.30% examples, 61492 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:36: EPOCH 4 - PROGRESS: at 91.98% examples, 59761 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:56:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:36: EPOCH - 4 : training on 523700 raw words (199150 effective words) took 3.3s, 60390 effective words/s\n",
            "INFO - 13:56:37: EPOCH 5 - PROGRESS: at 29.42% examples, 60462 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:38: EPOCH 5 - PROGRESS: at 63.30% examples, 62097 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:39: EPOCH 5 - PROGRESS: at 95.68% examples, 62483 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:39: EPOCH - 5 : training on 523700 raw words (199540 effective words) took 3.2s, 63102 effective words/s\n",
            "INFO - 13:56:40: EPOCH 6 - PROGRESS: at 31.39% examples, 60826 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:41: EPOCH 6 - PROGRESS: at 65.21% examples, 62226 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:56:42: EPOCH 6 - PROGRESS: at 97.45% examples, 62656 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:42: EPOCH - 6 : training on 523700 raw words (199462 effective words) took 3.2s, 62962 effective words/s\n",
            "INFO - 13:56:43: EPOCH 7 - PROGRESS: at 31.39% examples, 60865 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:44: EPOCH 7 - PROGRESS: at 65.21% examples, 62615 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:45: EPOCH 7 - PROGRESS: at 93.81% examples, 60220 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:46: EPOCH - 7 : training on 523700 raw words (199000 effective words) took 3.3s, 61090 effective words/s\n",
            "INFO - 13:56:47: EPOCH 8 - PROGRESS: at 31.39% examples, 60458 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:48: EPOCH 8 - PROGRESS: at 65.21% examples, 62111 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:56:49: EPOCH 8 - PROGRESS: at 97.45% examples, 62767 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:49: EPOCH - 8 : training on 523700 raw words (199266 effective words) took 3.2s, 63109 effective words/s\n",
            "INFO - 13:56:50: EPOCH 9 - PROGRESS: at 31.39% examples, 61520 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:51: EPOCH 9 - PROGRESS: at 65.21% examples, 60986 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:52: EPOCH 9 - PROGRESS: at 97.45% examples, 62030 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:52: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:52: EPOCH - 9 : training on 523700 raw words (199201 effective words) took 3.2s, 62465 effective words/s\n",
            "INFO - 13:56:53: EPOCH 10 - PROGRESS: at 29.42% examples, 59924 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:54: EPOCH 10 - PROGRESS: at 63.30% examples, 61591 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:55: EPOCH 10 - PROGRESS: at 91.98% examples, 59778 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:55: EPOCH - 10 : training on 523700 raw words (199075 effective words) took 3.3s, 60420 effective words/s\n",
            "INFO - 13:56:56: EPOCH 11 - PROGRESS: at 31.39% examples, 62268 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:57: EPOCH 11 - PROGRESS: at 65.21% examples, 62065 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:58: EPOCH 11 - PROGRESS: at 97.45% examples, 62896 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:56:58: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:56:58: EPOCH - 11 : training on 523700 raw words (199385 effective words) took 3.2s, 63234 effective words/s\n",
            "INFO - 13:56:59: EPOCH 12 - PROGRESS: at 31.39% examples, 61503 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:00: EPOCH 12 - PROGRESS: at 65.21% examples, 61927 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:01: EPOCH 12 - PROGRESS: at 97.45% examples, 61972 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:02: EPOCH - 12 : training on 523700 raw words (198819 effective words) took 3.2s, 62426 effective words/s\n",
            "INFO - 13:57:03: EPOCH 13 - PROGRESS: at 31.39% examples, 61525 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:04: EPOCH 13 - PROGRESS: at 63.30% examples, 58502 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:05: EPOCH 13 - PROGRESS: at 95.68% examples, 59663 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:05: EPOCH - 13 : training on 523700 raw words (199107 effective words) took 3.3s, 60506 effective words/s\n",
            "INFO - 13:57:06: EPOCH 14 - PROGRESS: at 29.42% examples, 60445 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:07: EPOCH 14 - PROGRESS: at 63.30% examples, 62096 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:08: EPOCH 14 - PROGRESS: at 95.68% examples, 62148 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:08: EPOCH - 14 : training on 523700 raw words (199018 effective words) took 3.2s, 62630 effective words/s\n",
            "INFO - 13:57:09: EPOCH 15 - PROGRESS: at 31.39% examples, 61232 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:10: EPOCH 15 - PROGRESS: at 65.21% examples, 61993 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:11: EPOCH 15 - PROGRESS: at 97.45% examples, 62854 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:11: EPOCH - 15 : training on 523700 raw words (199635 effective words) took 3.2s, 62982 effective words/s\n",
            "INFO - 13:57:12: EPOCH 16 - PROGRESS: at 29.42% examples, 58411 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:13: EPOCH 16 - PROGRESS: at 59.44% examples, 57259 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:14: EPOCH 16 - PROGRESS: at 91.98% examples, 59401 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:15: EPOCH - 16 : training on 523700 raw words (199205 effective words) took 3.3s, 60238 effective words/s\n",
            "INFO - 13:57:16: EPOCH 17 - PROGRESS: at 31.39% examples, 60731 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:17: EPOCH 17 - PROGRESS: at 65.21% examples, 62277 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:18: EPOCH 17 - PROGRESS: at 97.45% examples, 62800 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:18: EPOCH - 17 : training on 523700 raw words (199196 effective words) took 3.2s, 63096 effective words/s\n",
            "INFO - 13:57:19: EPOCH 18 - PROGRESS: at 31.39% examples, 60683 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:20: EPOCH 18 - PROGRESS: at 65.21% examples, 61328 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:21: EPOCH 18 - PROGRESS: at 97.45% examples, 62195 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:21: EPOCH - 18 : training on 523700 raw words (199097 effective words) took 3.2s, 62709 effective words/s\n",
            "INFO - 13:57:22: EPOCH 19 - PROGRESS: at 29.42% examples, 59436 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:23: EPOCH 19 - PROGRESS: at 59.44% examples, 57796 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:24: EPOCH 19 - PROGRESS: at 91.98% examples, 60021 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:24: EPOCH - 19 : training on 523700 raw words (199697 effective words) took 3.3s, 60516 effective words/s\n",
            "INFO - 13:57:25: EPOCH 20 - PROGRESS: at 31.39% examples, 61125 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:26: EPOCH 20 - PROGRESS: at 65.21% examples, 62192 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:27: EPOCH 20 - PROGRESS: at 97.45% examples, 62084 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:27: EPOCH - 20 : training on 523700 raw words (199491 effective words) took 3.2s, 62518 effective words/s\n",
            "INFO - 13:57:28: EPOCH 21 - PROGRESS: at 31.39% examples, 61918 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:29: EPOCH 21 - PROGRESS: at 65.21% examples, 62161 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:31: EPOCH 21 - PROGRESS: at 97.45% examples, 62229 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:31: EPOCH - 21 : training on 523700 raw words (198582 effective words) took 3.2s, 62748 effective words/s\n",
            "INFO - 13:57:32: EPOCH 22 - PROGRESS: at 31.39% examples, 61416 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:33: EPOCH 22 - PROGRESS: at 53.70% examples, 50058 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:34: EPOCH 22 - PROGRESS: at 82.28% examples, 52257 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:34: EPOCH - 22 : training on 523700 raw words (199255 effective words) took 3.7s, 54263 effective words/s\n",
            "INFO - 13:57:35: EPOCH 23 - PROGRESS: at 31.39% examples, 62195 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:36: EPOCH 23 - PROGRESS: at 65.21% examples, 61994 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:37: EPOCH 23 - PROGRESS: at 97.45% examples, 62223 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:37: EPOCH - 23 : training on 523700 raw words (199012 effective words) took 3.2s, 62931 effective words/s\n",
            "INFO - 13:57:39: EPOCH 24 - PROGRESS: at 31.39% examples, 60355 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:40: EPOCH 24 - PROGRESS: at 51.79% examples, 45642 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:41: EPOCH 24 - PROGRESS: at 65.21% examples, 39629 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:42: EPOCH 24 - PROGRESS: at 80.39% examples, 37469 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:43: EPOCH 24 - PROGRESS: at 99.32% examples, 37379 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:43: EPOCH - 24 : training on 523700 raw words (198827 effective words) took 5.3s, 37465 effective words/s\n",
            "INFO - 13:57:44: EPOCH 25 - PROGRESS: at 16.67% examples, 32265 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:45: EPOCH 25 - PROGRESS: at 49.85% examples, 44908 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:46: EPOCH 25 - PROGRESS: at 82.28% examples, 50284 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:47: EPOCH - 25 : training on 523700 raw words (199315 effective words) took 3.8s, 52604 effective words/s\n",
            "INFO - 13:57:48: EPOCH 26 - PROGRESS: at 31.39% examples, 61045 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:49: EPOCH 26 - PROGRESS: at 65.21% examples, 61438 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:50: EPOCH 26 - PROGRESS: at 97.45% examples, 62339 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:50: EPOCH - 26 : training on 523700 raw words (199170 effective words) took 3.2s, 62558 effective words/s\n",
            "INFO - 13:57:51: EPOCH 27 - PROGRESS: at 29.42% examples, 60468 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:52: EPOCH 27 - PROGRESS: at 63.30% examples, 61352 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:53: EPOCH 27 - PROGRESS: at 95.68% examples, 62083 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:53: EPOCH - 27 : training on 523700 raw words (199503 effective words) took 3.2s, 62593 effective words/s\n",
            "INFO - 13:57:54: EPOCH 28 - PROGRESS: at 31.39% examples, 60974 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:55: EPOCH 28 - PROGRESS: at 61.40% examples, 59002 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:56: EPOCH 28 - PROGRESS: at 93.81% examples, 60308 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:56: EPOCH - 28 : training on 523700 raw words (199304 effective words) took 3.3s, 60871 effective words/s\n",
            "INFO - 13:57:57: EPOCH 29 - PROGRESS: at 29.42% examples, 60071 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:58: EPOCH 29 - PROGRESS: at 63.30% examples, 61358 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:57:59: EPOCH 29 - PROGRESS: at 95.68% examples, 62272 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 13:57:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:57:59: EPOCH - 29 : training on 523700 raw words (199329 effective words) took 3.2s, 62756 effective words/s\n",
            "INFO - 13:58:00: EPOCH 30 - PROGRESS: at 29.42% examples, 60289 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:58:01: EPOCH 30 - PROGRESS: at 63.30% examples, 61086 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:58:03: EPOCH 30 - PROGRESS: at 95.68% examples, 61951 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 13:58:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 13:58:03: EPOCH - 30 : training on 523700 raw words (198902 effective words) took 3.2s, 62228 effective words/s\n",
            "INFO - 13:58:03: training on a 15711000 raw words (5975803 effective words) took 100.8s, 59291 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to train the model: 1.68 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.init_sims(replace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7DUi3_4qeMI",
        "outputId": "37b2bb73-3c8d-4074-eb9d-92a38ad38e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 13:58:14: precomputing L2-norms of word weight vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKzwkSJ4q6FC",
        "outputId": "ca20bda8-cc9a-444e-cbb2-ac1abc37e4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('recent', 0.7703971862792969),\n",
              " ('council', 0.7655794024467468),\n",
              " ('governor', 0.7636814117431641),\n",
              " ('congratulation', 0.7545962333679199),\n",
              " ('easily', 0.7522720694541931),\n",
              " ('erotic', 0.7426029443740845),\n",
              " ('committee', 0.7418639659881592),\n",
              " ('robert', 0.7410692572593689),\n",
              " ('defeat', 0.7407906651496887),\n",
              " ('pleased', 0.7378360629081726)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"marge\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESMVkNXUq9Hy",
        "outputId": "0999d5c1-cd3c-41f0-9a59-a62d30a27344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('convince', 0.7846249341964722),\n",
              " ('homer', 0.7692607641220093),\n",
              " ('becky', 0.7607318162918091),\n",
              " ('rude', 0.753149151802063),\n",
              " ('raccoon', 0.7525891661643982),\n",
              " ('sorry', 0.7513182163238525),\n",
              " ('grownup', 0.7488009929656982),\n",
              " ('fault', 0.7467668056488037),\n",
              " ('spoil', 0.7458378076553345),\n",
              " ('brunch', 0.7453069090843201)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"bart\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoqzqUtqq_96",
        "outputId": "65cbeab2-84df-4906-db01-bf7758aaacbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.8530301451683044),\n",
              " ('homework', 0.8104968070983887),\n",
              " ('surprised', 0.793811023235321),\n",
              " ('upset', 0.7883384823799133),\n",
              " ('mom', 0.7870502471923828),\n",
              " ('typical', 0.775067925453186),\n",
              " ('convince', 0.7662098407745361),\n",
              " ('substitute', 0.7661116123199463),\n",
              " ('strangle', 0.7621992230415344),\n",
              " ('hearing', 0.762141227722168)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('maggie', 'baby')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXod4iQArDhJ",
        "outputId": "80dc4da6-72a6-4f86-9f3f-1b6b51f9d594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7096791"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('bart', 'nelson')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdeLJqoprREh",
        "outputId": "976faaf0-0523-4eb5-98a2-41adfe5ad418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6498818"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Lv128IPErXiu",
        "outputId": "f1ce60e1-7b27-4eff-9824-8563faea773c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - 14:00:20: vectors for words {'kearney'} are not present in the model, ignoring these words\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'milhouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "aTrVDQ4Krbqs",
        "outputId": "b159c13d-2b43-4756-8060-58806ed47b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nelson'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.doesnt_match(['homer', 'patty', 'selma'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "y29Yn0o8regp",
        "outputId": "353e86a2-dbfe-4986-eb8a-e2c3e54b56c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'homer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4dkr84nremm",
        "outputId": "7c609e16-4ce2-4f70-c7c5-9ef04cefd3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('admire', 0.6912828683853149),\n",
              " ('carefully', 0.6303946375846863),\n",
              " ('obvious', 0.6277869343757629)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgfwExMkrnqS",
        "outputId": "8c38053c-cb99-45d4-9970-c5c8320af91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.7569124698638916),\n",
              " ('upset', 0.7464685440063477),\n",
              " ('parent', 0.7420808672904968)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}